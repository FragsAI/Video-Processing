{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76d4f952-c6d0-417d-872a-519af637be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101e082-30db-423f-9e6c-877f9023a70f",
   "metadata": {},
   "source": [
    "1. Video Processing:\n",
    "Integrate a video processing library (e.g., OpenCV, FFmpeg) to handle video decoding, frame extraction, and other video manipulation tasks.\n",
    "Implement functionality to read input video streams, extract individual frames, and prepare data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09f33fb8-f957-4150-8001-040bcbe75e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    '''input: frames\n",
    "       output : edges\n",
    "       This function takes in a frame and preprocessing it -> Convert image to grayscale, \n",
    "       apply guassian blur and detect edges in the blurred image'''\n",
    "   \n",
    "    # Convert the image to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to the grayscale image\n",
    "    blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "    \n",
    "    # Do edge detection\n",
    "    edges = cv2.Canny(blurred_frame, 50, 150)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7a9c46d-7a09-4585-a99e-988ef6eab22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Error: Unable to open video file.\")\n",
    "        return\n",
    "        \n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_filename = f\"frame_{frame_count}.jpg\"\n",
    "        processed_frame=preprocess_frame(frame)\n",
    "        cv2.imwrite(os.path.join(output_folder, frame_filename), processed_frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    video_capture.release()\n",
    "    print(f\"{frame_count} Frames extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0b6cb26-b619-4d15-8722-c39402c4fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647 Frames extracted\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "video_path = 'person-bicycle-car-detection.mp4'\n",
    "output_folder = 'ProcessedOutput'\n",
    "extract_frames(video_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c439f0-2b70-4d94-9b54-f1624a849bc1",
   "metadata": {},
   "source": [
    "2. Shot Boundary Detection:\n",
    "Develop algorithms or techniques to detect transitions between shots or scenes in the video, such as comparing histogram differences or edge changes between consecutive frames.\n",
    "Implement shot boundary detection to identify potential points in the video where a new clip could begin or end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c28cf207-bf94-4f62-9d8c-582d5a9e8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_shot_boundaries(video_path):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    prev_frame = None\n",
    "    shot_boundaries = []\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break    \n",
    "        processed_frame = preprocess_frame(frame)\n",
    "        if prev_frame is not None:\n",
    "            frame_diff = cv2.absdiff(processed_frame, preprocess_frame(prev_frame))\n",
    "            diff = cv2.countNonZero(frame_diff)\n",
    "            ## THis is the threshold to adjust\n",
    "            if diff > 2000: \n",
    "                shot_boundaries.append(video_capture.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        prev_frame = frame\n",
    "    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return shot_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8380d-eed7-455f-81c0-a881ca992829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a9ad835-1072-4597-b9ad-3dda6af8daf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected shot boundaries at frames: [8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 120.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 229.0, 230.0, 231.0, 233.0, 329.0, 330.0, 343.0, 502.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 582.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0]\n"
     ]
    }
   ],
   "source": [
    "shot_boundaries = detect_shot_boundaries(video_path)\n",
    "print(\"Detected shot boundaries at frames:\", shot_boundaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
